{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1757715",
   "metadata": {},
   "source": [
    "# TweepFake - Twitter deep Fake text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5fafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4868fd",
   "metadata": {},
   "source": [
    "# Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cb134e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"D://Dataset//Twiter//archive (4)\\\\test.csv\")\n",
    "df2 = pd.read_csv(\"D://Dataset//Twiter//archive (4)\\\\train.csv\")\n",
    "df3 = pd.read_csv(\"D://Dataset//Twiter//archive (4)\\\\validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e94ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the datasets into a single DataFrame\n",
    "df = pd.concat([df1,df2,df3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5940b0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Dataset info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25572 entries, 0 to 25571\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   user_id       25572 non-null  object\n",
      " 1   status_id     25572 non-null  object\n",
      " 2   screen_name   25572 non-null  object\n",
      " 3   account.type  25572 non-null  object\n",
      " 4   class_type    25572 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 999.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the concatenate dataset\n",
    "print(\"Concatenated Dataset info\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76c08d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics\n",
      "<bound method NDFrame.describe of                    user_id            status_id screen_name account.type  \\\n",
      "0               3171109449  1123915745178656769    human#17        human   \n",
      "1                 18839785  1173906284195852290    human#11        human   \n",
      "2                343587159  1197343799846027265     human#1        human   \n",
      "3      1197916267975335939  1208274159274475521      bot#12          bot   \n",
      "4                 15088390  1084181032927059970    human#10        human   \n",
      "...                    ...                  ...         ...          ...   \n",
      "25567   705113652471439361   714523361305608192      bot#16          bot   \n",
      "25568            262794965   935057601103933441     human#8        human   \n",
      "25569            343587159  1158520796039405569     human#1        human   \n",
      "25570  1110407881030017024  1210364706457677824       bot#9          bot   \n",
      "25571  1213988022728810496  1219363974657052675       bot#8          bot   \n",
      "\n",
      "      class_type  \n",
      "0          human  \n",
      "1          human  \n",
      "2          human  \n",
      "3            rnn  \n",
      "4          human  \n",
      "...          ...  \n",
      "25567        rnn  \n",
      "25568      human  \n",
      "25569      human  \n",
      "25570     others  \n",
      "25571       gpt2  \n",
      "\n",
      "[25572 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics  of the concatenated dataset\n",
    "print(\"\\nSummary Statistics\")\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f740bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Vlaues\n",
      "user_id         0\n",
      "status_id       0\n",
      "screen_name     0\n",
      "account.type    0\n",
      "class_type      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in concatenated dataset\n",
    "print(\"\\nMissing Vlaues\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3940ee5",
   "metadata": {},
   "source": [
    "# Perform data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a047a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example : Drop duplicates and handle missing values\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d4655da",
   "metadata": {},
   "source": [
    "# Split the data into features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bcab1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features X and target (y)\n",
    "X = df ['screen_name']\n",
    "y = df ['class_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17899eb",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ab5543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fbeb067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Vectorize the text data using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490800b9",
   "metadata": {},
   "source": [
    "# Vectorize the text data using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a868f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer the test data using CountVectorizer\n",
    "vectroizer  = CountVectorizer()\n",
    "X_train_vectorized = vectroizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectroizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f54f8d8",
   "metadata": {},
   "source": [
    "# Evaluate Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e272cc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a basic text classification model (Naive Bayes)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f1df7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a8a7ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model accuracy :90.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel accuracy :{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "74ccfa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gpt2       1.00      0.37      0.54       785\n",
      "       human       1.00      1.00      1.00      2549\n",
      "      others       0.66      1.00      0.80       984\n",
      "         rnn       1.00      0.98      0.99       796\n",
      "\n",
      "    accuracy                           0.90      5114\n",
      "   macro avg       0.91      0.84      0.83      5114\n",
      "weighted avg       0.93      0.90      0.89      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report and confusion matrix\n",
    "print(\"\\n Classification Report\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d77373c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion Matrix :\n",
      "[[ 294    0  491    0]\n",
      " [   0 2549    0    0]\n",
      " [   0    0  984    0]\n",
      " [   0    0   16  780]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4639be",
   "metadata": {},
   "source": [
    "# Evaluate Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f60d47a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train a Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "132956bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr_classifier.predict(X_test_vectorized)\n",
    "lr_accuracy = accuracy_score(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ba53fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression Model:\n",
      "Accuracy:90.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Logistic Regression Model:\")\n",
    "print(f\"Accuracy:{lr_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9ff31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gpt2       0.63      1.00      0.77       785\n",
      "       human       1.00      1.00      1.00      2549\n",
      "      others       1.00      0.54      0.70       984\n",
      "         rnn       1.00      0.98      0.99       796\n",
      "\n",
      "    accuracy                           0.91      5114\n",
      "   macro avg       0.91      0.88      0.87      5114\n",
      "weighted avg       0.94      0.91      0.91      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nclassification_report\")\n",
    "print(classification_report(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0500be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix\n",
      "[[ 785    0    0    0]\n",
      " [   0 2549    0    0]\n",
      " [ 452    0  532    0]\n",
      " [  16    0    0  780]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nconfusion_matrix\")\n",
    "print(confusion_matrix(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff56ed",
   "metadata": {},
   "source": [
    "# Evaluate Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c9d50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_vectorized,y_train)\n",
    "rf_pred = rf_classifier.predict(X_test_vectorized)\n",
    "rf_accuracy = accuracy_score(y_test,rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0374679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Model\n",
      "accuracy:90.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Random Forest Model\")\n",
    "print(f\"accuracy:{rf_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e1b71f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gpt2       0.63      1.00      0.77       785\n",
      "       human       1.00      1.00      1.00      2549\n",
      "      others       1.00      0.54      0.70       984\n",
      "         rnn       1.00      0.98      0.99       796\n",
      "\n",
      "    accuracy                           0.91      5114\n",
      "   macro avg       0.91      0.88      0.87      5114\n",
      "weighted avg       0.94      0.91      0.91      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44c03c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 785    0    0    0]\n",
      " [   0 2549    0    0]\n",
      " [ 452    0  532    0]\n",
      " [  16    0    0  780]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a6055",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "126fef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Train a Support Vector Machine classifier\n",
    "svm_classifier = SVC(kernel = 'linear', C=1.0)\n",
    "svm_classifier.fit(X_train_vectorized, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76fad4",
   "metadata": {},
   "source": [
    "# Evaluate the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "358ba4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm_classifier.predict(X_test_vectorized)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7bd3f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n Support Vector Machine\n",
      "Accuracy: 90.85%\n"
     ]
    }
   ],
   "source": [
    "# Display evaluation matrices for SVM\n",
    "print(\"/n Support Vector Machine\")\n",
    "print(f\"Accuracy: {svm_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a4bd0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nClassification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gpt2       0.63      1.00      0.77       785\n",
      "       human       1.00      1.00      1.00      2549\n",
      "      others       1.00      0.54      0.70       984\n",
      "         rnn       1.00      0.98      0.99       796\n",
      "\n",
      "    accuracy                           0.91      5114\n",
      "   macro avg       0.91      0.88      0.87      5114\n",
      "weighted avg       0.94      0.91      0.91      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/nClassification Report\")\n",
    "print(classification_report(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7fd6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 785    0    0    0]\n",
      " [   0 2549    0    0]\n",
      " [ 452    0  532    0]\n",
      " [  16    0    0  780]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65942d7b",
   "metadata": {},
   "source": [
    "# Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5df28cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Train a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100,random_state=42)\n",
    "gb_classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec5e1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Gradient Boosting model\n",
    "gb_pred = gb_classifier.predict(X_test_vectorized)\n",
    "gb_accuracy = accuracy_score(y_test,gb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "54c00d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Model\n",
      "Accuracy:90.85%\n"
     ]
    }
   ],
   "source": [
    "# Display evaluation metrics for Gradient Boosting\n",
    "print(\"\\nGradient Boosting Model\")\n",
    "print(f\"Accuracy:{gb_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8cb3bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gpt2       0.63      1.00      0.77       785\n",
      "       human       1.00      1.00      1.00      2549\n",
      "      others       1.00      0.54      0.70       984\n",
      "         rnn       1.00      0.98      0.99       796\n",
      "\n",
      "    accuracy                           0.91      5114\n",
      "   macro avg       0.91      0.88      0.87      5114\n",
      "weighted avg       0.94      0.91      0.91      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3be1719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 785    0    0    0]\n",
      " [   0 2549    0    0]\n",
      " [ 452    0  532    0]\n",
      " [  16    0    0  780]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7804df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
