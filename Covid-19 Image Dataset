{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1117472,"sourceType":"datasetVersion","datasetId":627146}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport warnings\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom PIL import Image\nfrom copy import deepcopy\n\nwarnings.filterwarnings(\"ignore\")\n\n# Define the create_df function\ndef create_df(path):\n    dd = {\"images\": [], \"labels\": []}\n    \n    for i in os.listdir(path):\n        img_dirs = os.path.join(path, i)\n        for j in os.listdir(img_dirs):\n            dd[\"images\"].append(os.path.join(img_dirs, j))\n            dd[\"labels\"].append(i)\n            \n    return pd.DataFrame(dd)\n\n# Importing data\ndf = create_df(\"/kaggle/input/covid19-image-dataset/Covid19-dataset/train\")\ntest = create_df(\"/kaggle/input/covid19-image-dataset/Covid19-dataset/test\")\n\n# Encoding labels and shuffling test set\nle = LabelEncoder()\ndf[\"labels\"] = le.fit_transform(df[\"labels\"].values)\ntest[\"labels\"] = le.transform(test[\"labels\"].values)\ntest = test.sample(frac=1).reset_index(drop=True)\n\n# Hyperparameters\nEPOCHS = 20\nLR = 0.1\nGAMMA = 0.1\nSTEP = 10\nBATCH = 32\nIMG_SIZE = 224\nOUT_SIZE = 3\n\n# Splitting data\ntrain, val = train_test_split(df.values, random_state=42, test_size=0.2)\n\n# Data transformation pipeline\nclass Pipeline(Dataset):\n    def __init__(self, data, transform):\n        super(Pipeline, self).__init__()\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, x):\n        img, label = self.data[x, 0], self.data[x, 1]\n        img = Image.open(img).convert(\"RGB\")\n        img = np.array(img)\n        img = self.transform(img)\n        return img, label\n\n# Data preprocessing setup\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_ds = Pipeline(train, transform)\nval_ds = Pipeline(val, transform)\n\ntrain_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n\n# Define ResNet50\nresnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\nnum_ftrs = resnet.fc.in_features\nresnet.fc = nn.Linear(num_ftrs, OUT_SIZE)\n\n# Adding softmax layer to pre-trained ResNet50\nclass COVID_Detector(nn.Module):\n    def __init__(self, model):\n        super(COVID_Detector, self).__init__()\n        self.model = model\n        \n    def forward(self, x):\n        return nn.functional.softmax(self.model(x), dim=1)\n\n# Training device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\n\n# Training settings\nmodel = COVID_Detector(resnet)\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n\n# Training\nbest_model = deepcopy(model)\nbest_acc = 0\n\ntrain_loss = []\ntrain_acc = []\nval_loss = []\nval_acc = []\n\nfor i in range(1, EPOCHS+1):\n    model.train()\n    \n    diff = 0\n    acc = 0\n    total = 0\n    \n    for data, target in train_dl:\n        optimizer.zero_grad()\n        \n        if torch.cuda.is_available():\n            data, target = data.cuda(), target.cuda()\n            \n        out = model(data)\n        loss = criterion(out, target)\n        diff += loss.item()\n        acc += (out.argmax(1) == target).sum().item()\n        total += out.size(0)\n        loss.backward()\n        optimizer.step()\n    train_loss.append(diff/total)\n    train_acc.append(acc/total)\n    \n    model.eval()\n    \n    diff = 0\n    acc = 0\n    total = 0\n    \n    with torch.no_grad():\n        for data, target in val_dl:\n            if torch.cuda.is_available():\n                data, target = data.cuda(), target.cuda()\n            out = model(data)\n            loss = criterion(out, target)\n            diff += loss.item()\n            acc += (out.argmax(1) == target).sum().item()\n            total += out.size(0)\n\n    val_loss.append(diff/total)\n    val_acc.append(acc/total)\n    \n    if best_acc < val_acc[-1]:\n        best_acc = val_acc[-1]\n        best_model = deepcopy(model)\n    \n    print(f\"Epoch {i} train loss {train_loss[-1]} acc {train_acc[-1]} val loss {val_loss[-1]} acc {val_acc[-1]}\")\n    \n    scheduler.step()\n\n# Prediction\ndef predict(img_path):\n    img = Image.open(img_path).convert(\"RGB\")\n    img = np.array(img)\n    img = transform(img)\n    img = img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output = best_model(img)\n        proba, pred = torch.max(output, 1)\n    return pred.item(), proba.item()\n\ntruth = []\nprobas = []\npreds = []\n\nfor i in range(test.shape[0]):\n    pred, proba = predict(test.iloc[i, 0])\n    truth.append(test.iloc[i, 1])\n    preds.append(pred)\n    probas.append(proba * 100)\n\n# Evaluation metrics\nprint(classification_report(truth, preds))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}