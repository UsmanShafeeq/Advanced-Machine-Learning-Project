{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6989ec60",
   "metadata": {},
   "source": [
    "# Language Detection with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6309ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a80246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for Language Classifier\n",
    "class LanguageClassifer:\n",
    "    def __init__(self, data_url):\n",
    "        self.data_url = data_url # Constructor to initialize data URL and necessary objects\n",
    "        self.data = None # Initialize data as None\n",
    "        self.cv = CountVectorizer() # Initialize CountVectorizer for text processing\n",
    "        self.model = MultinomialNB()# Initialize Multinomial Naive Bayes model for language classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25735a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self):\n",
    "    # Method to load and explore the dataset\n",
    "    self.data = pd.read_csv(self.data_url)  # Read data from the provided URL\n",
    "    print(\"Dataset Sample:\\n\", self.data.head())  # Display the first few rows of the dataset\n",
    "    missing_values = self.data.isnull().sum() # Count missing values in the dataset\n",
    "    print('Missing Values:\\n',self.data.head()) # Display the first few rows of the dataset\n",
    "    lanugage_counts = self.data[\"language\"].value_counts()# Count occurrences of each language\n",
    "    print('Language Counts:\\n',language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd987ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(self):\n",
    "    # Method to preprocess the data\n",
    "    X = self.data['Text'] # Extract text data\n",
    "    y = self.data[\"language\"] # Extract language labels\n",
    "    X = self.cv.fit_transform(X) # Transform text data into numerical format\n",
    "    self.X_train,self.X_test,self.y_train,self.y_test = train_test_split(X,y,test_size=0.33,rabdom_state=42)\n",
    "    # Split data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53bdf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(self):\n",
    "    # Method to train the language classification model\n",
    "    self.model.fit(self.X_train, self.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd79e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sample:\n",
      "                                                 Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
      "Missing Values:\n",
      " Text        0\n",
      "language    0\n",
      "dtype: int64\n",
      "Language Counts:\n",
      " Estonian      1000\n",
      "Swedish       1000\n",
      "English       1000\n",
      "Russian       1000\n",
      "Romanian      1000\n",
      "Persian       1000\n",
      "Pushto        1000\n",
      "Spanish       1000\n",
      "Hindi         1000\n",
      "Korean        1000\n",
      "Chinese       1000\n",
      "French        1000\n",
      "Portugese     1000\n",
      "Indonesian    1000\n",
      "Urdu          1000\n",
      "Latin         1000\n",
      "Turkish       1000\n",
      "Japanese      1000\n",
      "Dutch         1000\n",
      "Tamil         1000\n",
      "Thai          1000\n",
      "Arabic        1000\n",
      "Name: language, dtype: int64\n",
      "Enter a Text: Indonesian\n",
      "Predicted Language: ['Thai']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_url = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\"\n",
    "    # Create an instance of LanguageClassifier\n",
    "    classifer = LanguageClassifier(data_url)\n",
    "    # Run the language classification process\n",
    "    classifer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21ce05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
