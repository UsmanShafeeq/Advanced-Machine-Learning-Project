{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCT4ZZs9L3m2DhHADz4YD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UsmanShafeeq/Advanced-Machine-Learning-Project/blob/main/Medical_Cost_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Cost Analysis"
      ],
      "metadata": {
        "id": "6ZqGH4QTSvK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "The Medical Cost Analysis project aims to predict healthcare costs using machine learning techniques. It identifies key cost-driving factors and provides insights to optimize medical expenditures. The project leverages real-world datasets for analysis and prediction."
      ],
      "metadata": {
        "id": "W8_YXZQhUDrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Important Libraries"
      ],
      "metadata": {
        "id": "ucFSCagXUVkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.warn(\"this will not show\")"
      ],
      "metadata": {
        "id": "lIyd9gUOS9Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Data Collection and Description"
      ],
      "metadata": {
        "id": "tyw-U7aSUQ8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle"
      ],
      "metadata": {
        "id": "-TNsgIM4Vb35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl5hiSHDSdWg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Download the Kaggle dataset\n",
        "def download_dataset():\n",
        "    dataset = \"mirichoi0218/insurance\"\n",
        "    download_path = \"datasets/insurance\"\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "    # Use Kaggle API to download the dataset\n",
        "    os.system(f\"kaggle datasets download -d {dataset} -p {download_path} --unzip\")\n",
        "    print(f\"Dataset downloaded to {download_path}\")\n",
        "    return f\"{download_path}/insurance.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "def load_dataset():\n",
        "    path = download_dataset()\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "# Use the function to read the dataset\n",
        "df = load_dataset()\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Display Basic Information"
      ],
      "metadata": {
        "id": "XzzgO27oV-yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "NSFZdd6CVzXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display last row about data\n",
        "df1.tail()"
      ],
      "metadata": {
        "id": "gFBmGwUeV3TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random sample about data\n",
        "df1.sample(5)"
      ],
      "metadata": {
        "id": "LKtYfTu8WDXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information about the dataset\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "mh749RnFWhfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "3qlnAQBzWzui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display column names\n",
        "df1.columns.tolist()"
      ],
      "metadata": {
        "id": "dhn4xK8JW6Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display shape of the dataset (number of rows and columns)\n",
        "print(f\"Rows: {df1.shape[0]}, Columns: {df1.shape[1]}\")"
      ],
      "metadata": {
        "id": "eKV1Pi8GXJqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display statistical summary of numerical columns\n",
        "df1.describe(exclude = 'object').style.background_gradient(cmap='BuPu')"
      ],
      "metadata": {
        "id": "o8vF9IzPXQh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique values in each column\n",
        "print(\"\\nUnique Values in Each Column:\")\n",
        "for column in df1.columns:\n",
        "  print(f\"{column}:{df1[column].nunique()})\")"
      ],
      "metadata": {
        "id": "CHOp0PftX9Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "V8JAiCThVy4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot: charges vs. bmi\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='bmi', y='charges', data=df, color='blue', alpha=0.6)\n",
        "plt.title('Medical Charges vs. BMI')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Medical Charges')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "two3a0aBZPtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot: charges vs. age\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='age', y='charges', data=df, color='green', alpha=0.6)\n",
        "plt.title('Medical Charges vs. Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Medical Charges')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_5pEGxiZ4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot: charges vs. children\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='children', y='charges', data=df, color='orange', alpha=0.6)\n",
        "plt.title('Medical Charges vs. Number of Children')\n",
        "plt.xlabel('Number of Children')\n",
        "plt.ylabel('Medical Charges')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aYE-gZp1aPDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot to visualize relationships among numerical variables\n",
        "sns.pairplot(df[['age', 'bmi', 'children', 'charges']])\n",
        "plt.suptitle('Pairplot of Numerical Features', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05Td-sh6aTR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the correlation matrix\n",
        "corr_matrix = df[['age', 'bmi', 'children', 'charges']].corr()\n",
        "\n",
        "\n",
        "sns.set(style='white', palette='muted')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "heatmap = sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu',fmt='.2f',cbar=True, linewidths=0.5, linecolor='white',annot_kws={'size': 12, 'weight': 'bold', 'color': 'black'},\n",
        "    square=True,\n",
        "    vmin=-1, vmax=1\n",
        ")\n",
        "\n",
        "\n",
        "plt.title('Correlation Matrix of Numerical Features', fontsize=16, weight='bold', color='darkblue')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lMC3jT1jajBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boxplot for 'bmi'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='bmi', data=df, color='skyblue', linewidth=1.5)\n",
        "plt.title('Boxplot of BMI')\n",
        "plt.xlabel('BMI')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fki7vFmHa2wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boxplot for 'charges'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='charges', data=df, color='lightgreen', linewidth=1.5)\n",
        "plt.title('Boxplot of Medical Charges')\n",
        "plt.xlabel('Medical Charges')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9kcfQ6ikbqMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IQR for 'bmi'\n",
        "Q1_bmi = df['bmi'].quantile(0.25)\n",
        "Q3_bmi = df['bmi'].quantile(0.75)\n",
        "IQR_bmi = Q3_bmi - Q1_bmi\n",
        "lower_bound_bmi = Q1_bmi - 1.5 * IQR_bmi\n",
        "upper_bound_bmi = Q3_bmi + 1.5 * IQR_bmi\n",
        "\n",
        "# Find outliers in 'bmi'\n",
        "bmi_outliers = df[(df['bmi'] < lower_bound_bmi) | (df['bmi'] > upper_bound_bmi)]\n",
        "\n",
        "# Calculate IQR for 'charges'\n",
        "Q1_charges = df['charges'].quantile(0.25)\n",
        "Q3_charges = df['charges'].quantile(0.75)\n",
        "IQR_charges = Q3_charges - Q1_charges\n",
        "lower_bound_charges = Q1_charges - 1.5 * IQR_charges\n",
        "upper_bound_charges = Q3_charges + 1.5 * IQR_charges\n",
        "\n",
        "# Find outliers in 'charges'\n",
        "charges_outliers = df[(df['charges'] < lower_bound_charges) | (df['charges'] > upper_bound_charges)]\n",
        "\n",
        "# Display the number of outliers detected\n",
        "print(f\"Number of BMI outliers: {bmi_outliers.shape[0]}\")\n",
        "print(f\"Number of Charges outliers: {charges_outliers.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "8hKYWltHbvL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IQR for 'bmi'\n",
        "Q1_bmi = df['bmi'].quantile(0.25)\n",
        "Q3_bmi = df['bmi'].quantile(0.75)\n",
        "IQR_bmi = Q3_bmi - Q1_bmi\n",
        "lower_bound_bmi = Q1_bmi - 1.5 * IQR_bmi\n",
        "upper_bound_bmi = Q3_bmi + 1.5 * IQR_bmi\n",
        "\n",
        "# Calculate IQR for 'charges'\n",
        "Q1_charges = df['charges'].quantile(0.25)\n",
        "Q3_charges = df['charges'].quantile(0.75)\n",
        "IQR_charges = Q3_charges - Q1_charges\n",
        "lower_bound_charges = Q1_charges - 1.5 * IQR_charges\n",
        "upper_bound_charges = Q3_charges + 1.5 * IQR_charges\n",
        "\n",
        "# Filter out the outliers from 'bmi' and 'charges'\n",
        "df_cleaned = df[(df['bmi'] >= lower_bound_bmi) & (df['bmi'] <= upper_bound_bmi) &\n",
        "                (df['charges'] >= lower_bound_charges) & (df['charges'] <= upper_bound_charges)]\n",
        "\n",
        "# Check the shape of the dataset before and after removing outliers\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
        "\n",
        "# Display first few rows of the cleaned dataset\n",
        "df_cleaned.head()\n"
      ],
      "metadata": {
        "id": "hO1ABdxub04U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development"
      ],
      "metadata": {
        "id": "IJsI0LmpdC54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split Code:**"
      ],
      "metadata": {
        "id": "fMNUur93dO__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature columns (X) and target column (y)\n",
        "X = df_cleaned[['age', 'bmi', 'children']]  # Independent variables\n",
        "y = df_cleaned['charges']  # Dependent variable (target)\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes of the resulting datasets\n",
        "print(f\"Training data shape: {X_train.shape}, Test data shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "jf1LZgZccQUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3 Baseline Model Selection"
      ],
      "metadata": {
        "id": "T-TSZ7sldh9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model: Linear Regression**"
      ],
      "metadata": {
        "id": "aM95tA4Rdn_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Instantiate the model\n",
        "baseline_model = LinearRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) for Baseline Model: {mse}\")\n",
        "print(f\"R-squared (R2) for Baseline Model: {r2}\")\n"
      ],
      "metadata": {
        "id": "BoRhuYSrdWLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - Mean Squared Error: {mse_rf}\")\n",
        "print(f\"Random Forest - R-squared: {r2_rf}\")\n"
      ],
      "metadata": {
        "id": "wK-tKs-xgDJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.4 Model Evaluation Metrics\n"
      ],
      "metadata": {
        "id": "_zKxIe2WgqA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mean Squared Error (MSE):"
      ],
      "metadata": {
        "id": "UV2b7wy2gvQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ],
      "metadata": {
        "id": "kZss5ysqgO0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Root Mean Squared Error (RMSE):"
      ],
      "metadata": {
        "id": "toMeKLbbg9s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n"
      ],
      "metadata": {
        "id": "oqKvpREHg50g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. R-squared (R²):"
      ],
      "metadata": {
        "id": "OtgOv2UNhBn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared: {r2}\")\n"
      ],
      "metadata": {
        "id": "zJwLmGewhQ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.5 Hyperparameter Tuning\n"
      ],
      "metadata": {
        "id": "oABI3pBwiQtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set up the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Regressor model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found by GridSearchCV\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
        "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
        "\n",
        "print(f\"Best Random Forest - Mean Squared Error: {mse_best_rf}\")\n",
        "print(f\"Best Random Forest - R-squared: {r2_best_rf}\")\n"
      ],
      "metadata": {
        "id": "dwtVYZoZhTbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.6 Model Comparison"
      ],
      "metadata": {
        "id": "TXru76KMiZLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store model evaluation metrics\n",
        "models = {\n",
        "    \"Linear Regression\": {\"mse\": mse, \"r2\": r2},\n",
        "    \"Random Forest\": {\"mse\": mse_rf, \"r2\": r2_rf},\n",
        "    \"Best Random Forest\": {\"mse\": mse_best_rf, \"r2\": r2_best_rf}\n",
        "}\n",
        "\n",
        "# Create a DataFrame to display results\n",
        "model_comparison = pd.DataFrame(models).T\n",
        "print(model_comparison)\n"
      ],
      "metadata": {
        "id": "vi3pmPH6iVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.7 Feature Importance Analysis"
      ],
      "metadata": {
        "id": "D65Alhdciiix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances from the Random Forest model\n",
        "feature_importances = best_rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": feature_importances\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Display the feature importance\n",
        "print(feature_importance_df)\n"
      ],
      "metadata": {
        "id": "-uXLrU3uijcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.8 Model Deployment (Optional)"
      ],
      "metadata": {
        "id": "NVgaHkkBiqDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(best_rf_model, 'medical_cost_prediction_model.pkl')\n",
        "\n",
        "# Load the model (for later use)\n",
        "model = joblib.load('medical_cost_prediction_model.pkl')\n",
        "\n",
        "# Use the model to make predictions\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "TyJtFTASisRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.9 Cross-Validation (Optional)"
      ],
      "metadata": {
        "id": "bmreON1_jtlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation with the random forest model\n",
        "cv_scores = cross_val_score(best_rf_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Convert negative MSE to positive MSE\n",
        "cv_scores = -cv_scores\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(f\"Cross-validation MSE scores: {cv_scores}\")\n",
        "print(f\"Mean MSE across all folds: {cv_scores.mean()}\")\n"
      ],
      "metadata": {
        "id": "qrtascvcjwCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.10 Learning Curves (Optional)"
      ],
      "metadata": {
        "id": "-l03fxYij2kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Get the learning curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(best_rf_model, X, y, cv=5)\n",
        "\n",
        "# Plot the learning curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_scores.mean(axis=1), label='Train Score', color='blue')\n",
        "plt.plot(train_sizes, test_scores.mean(axis=1), label='Test Score', color='red')\n",
        "plt.xlabel('Training Size')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Learning Curves for Random Forest Model')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rldPSkTyjxjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.11 Feature Engineering (Optional)"
      ],
      "metadata": {
        "id": "0mLMWh3tkChi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new feature: age times BMI interaction\n",
        "df['age_bmi_interaction'] = df['age'] * df['bmi']\n",
        "\n",
        "# Log transform the charges (since charges might have a skewed distribution)\n",
        "df['log_charges'] = np.log(df['charges'])\n"
      ],
      "metadata": {
        "id": "Aql-xo9rj7WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bin age into categories: 'Young', 'Middle-Aged', 'Old'\n",
        "df['age_category'] = pd.cut(df['age'], bins=[0, 30, 50, np.inf], labels=['Young', 'Middle-Aged', 'Old'])\n"
      ],
      "metadata": {
        "id": "pqpUTWI1kGky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = joblib.load('medical_cost_prediction_model.pkl')\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define an API endpoint to make predictions\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the input data from the request\n",
        "    data = request.get_json()\n",
        "\n",
        "    # Convert the data into a NumPy array (assuming the features are passed as JSON)\n",
        "    input_features = np.array([data['age'], data['bmi'], data['children'], data['sex_female'], data['sex_male'], data['smoker_no'], data['smoker_yes'], data['region_northeast'], data['region_northwest'], data['region_southeast'], data['region_southwest']]).reshape(1, -1)\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_features)\n",
        "\n",
        "    # Return the prediction as JSON\n",
        "    return jsonify({\"predicted_charges\": prediction[0]})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFTmdvMikJmW",
        "outputId": "c3ba9552-e7ee-4eb0-c52e-157a22331d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}